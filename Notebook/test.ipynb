{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First part: Clean and transform data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WARNING: ONLY RUN THESE CODES ONCE. IF YOU RUN IT AGAIN, YOU MAY BREAK THE CSV FILE. I HAVE A BOOKS_RAW.CSV FILE IN THE REPOSITORY, SO YOU CAN USE THAT AS THE ORIGINAL FILE. ALWAY MAKE A COPY OF THE ORIGINAL FILE BEFORE RUNNING THE CODES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error tokenizing data. C error: Expected 12 fields in line 3350, saw 13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('../Dataset/books.csv')\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By testing a simple pandas function, we can see that the file books.csv has an error in line 3350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12224,Streetcar Suburbs: The Process of Growth in Boston  1870-1900,Sam Bass Warner, Jr./Sam B. Warner,3.58,0674842111,9780674842113,en-US,236,61,6,4/20/2004,Harvard University Press\n",
      "\n",
      "The line 3350 has: 13 elements separated by commas\n"
     ]
    }
   ],
   "source": [
    "# print line 3350 of books.csv without using pandas, which is 3349 in python\n",
    "with open('../Dataset/books.csv', 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i == 3349:\n",
    "            print(line)\n",
    "            print(\"The line \"+ str(i+1) + \" has: \" + str(len(line.split(','))) + \" elements separated by commas\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the line, we can see that the error is caused by the authors column, which has a comma in the middle of the string, causing the csv file to read it as a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sam Bass Warner', ' Jr./Sam B. Warner']\n"
     ]
    }
   ],
   "source": [
    "with open('../Dataset/books.csv', 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i == 3349:\n",
    "            # print the authors\n",
    "            print(line.split(',')[2:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple fix of this error is to delete the comma infront of the 'Jr.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Dataset/books.csv', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "with open('../Dataset/books.csv', 'w', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(lines):\n",
    "        if i == 3349:\n",
    "            # concatenate the second and third element of the line and save it back to the file\n",
    "            line = line.split(',')\n",
    "            line[2] = line[2] + line[3]\n",
    "            line.pop(3)\n",
    "            f.write(','.join(line))\n",
    "        else:\n",
    "            f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, by running the first cell, we can see that the error is fixed, but there are still other errors in the file, the below code would fix the next one, in the line 4703."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error tokenizing data. C error: Expected 12 fields in line 4704, saw 13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('../Dataset/books.csv')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16914,The Tolkien Fan's Medieval Reader,David E. Smith (Turgon of TheOneRing.net, one of the founding members of this Tolkien website)/Verlyn Flieger/Turgon (=David E. Smith),3.58,1593600119,9781593600112,eng,400,26,4,4/6/2004,Cold Spring Press\n",
      "\n",
      "The line 4704 has: 13 elements separated by commas\n"
     ]
    }
   ],
   "source": [
    "with open('../Dataset/books.csv', 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i == 4703:\n",
    "            print(line)\n",
    "            print(\"The line \"+ str(i+1) + \" has: \" + str(len(line.split(','))) + \" elements separated by commas\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Dataset/books.csv', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "with open('../Dataset/books.csv', 'w', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(lines):\n",
    "        if i == 4703:\n",
    "            # concatenate the second and third element of the line and save it back to the file\n",
    "            line = line.split(',')\n",
    "            line[2] = line[2] + line[3]\n",
    "            line.pop(3)\n",
    "            f.write(','.join(line))\n",
    "        else:\n",
    "            f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22128,Patriots (The Coming Collapse),James Wesley, Rawles,3.63,156384155X,9781563841552,eng,342,38,4,1/15/1999,Huntington House Publishers\n",
      "\n",
      "The line 5879 has: 13 elements separated by commas\n"
     ]
    }
   ],
   "source": [
    "with open('../Dataset/books.csv', 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i == 5878:\n",
    "            print(line)\n",
    "            print(\"The line \"+ str(i+1) + \" has: \" + str(len(line.split(','))) + \" elements separated by commas\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Dataset/books.csv', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "with open('../Dataset/books.csv', 'w', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(lines):\n",
    "        if i == 5878:\n",
    "            # concatenate the second and third element of the line and save it back to the file\n",
    "            line = line.split(',')\n",
    "            line[2] = line[2] + line[3]\n",
    "            line.pop(3)\n",
    "            f.write(','.join(line))\n",
    "        else:\n",
    "            f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Dataset/books.csv', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "with open('../Dataset/books.csv', 'w', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(lines):\n",
    "        if i == 5878:\n",
    "            # modify the second part of the line by adding a slash after the string \"Wesley\"\n",
    "            line = line.split(',')\n",
    "            line[2] = line[2].replace('Wesley', 'Wesley /')\n",
    "            line = ','.join(line)\n",
    "        if not line.endswith('\\n'):\n",
    "            line += '\\n'\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEXT ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error tokenizing data. C error: Expected 12 fields in line 8981, saw 13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('../Dataset/books.csv')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34889,Brown's Star Atlas: Showing All The Bright Stars With Full Instructions How To Find And Use Them For Navigational Purposes And Department Of Trade Examinations.,Brown, Son & Ferguson,0.00,0851742718,9780851742717,eng,49,0,0,5/1/1977,Brown Son & Ferguson Ltd.\n",
      "\n",
      "The line 8981 has: 13 elements separated by commas\n"
     ]
    }
   ],
   "source": [
    "with open('../Dataset/books.csv', 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i == 8980:\n",
    "            print(line)\n",
    "            print(\"The line \"+ str(i+1) + \" has: \" + str(len(line.split(','))) + \" elements separated by commas\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Dataset/books.csv', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "with open('../Dataset/books.csv', 'w', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(lines):\n",
    "        if i == 8980:\n",
    "            # concatenate the second and third element of the line and save it back to the file\n",
    "            line = line.split(',')\n",
    "            line[2] = line[2] + line[3]\n",
    "            line.pop(3)\n",
    "            f.write(','.join(line))\n",
    "        else:\n",
    "            f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Dataset/books.csv', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "with open('../Dataset/books.csv', 'w', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(lines):\n",
    "        if i == 8980:\n",
    "            # modify the second part of the line by adding a slash after the string \"Wesley\"\n",
    "            line = line.split(',')\n",
    "            line[2] = line[2].replace('Brown', 'Brown /')\n",
    "            line = ','.join(line)\n",
    "        if not line.endswith('\\n'):\n",
    "            line += '\\n'\n",
    "        f.write(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
